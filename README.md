# LLM-Learning Repository
This repository contains a collection of projects and experiments developed while learning about **large language models (LLMs)**. It includes hands-on implementations using **Hugging Face Transformers**, covering topics such as:
* Prompt engineering
* In-context learning (zero-shot, one-shot, few-shot)
* Use FLAN-T5, a large language model fine-tuned with instruction-based tasks to follow natural language prompts
* Use mBART-50, a multilingual sequence-to-sequence model trained on many languages
* Translate input text

---

# üìù SummarizeDialogue.ipynb
* This file uses the **FLAN-T5 model** and **Hugging Face** to experiment with prompt engineering and in-context learning, including zero-shot, one-shot, and few-shot scenarios.

---

# üìù DialogueToFarsi.ipynb
* This file provides a simple example of translating text from Farsi (Persian) to English using the **facebook/mbart model** from **Hugging Face Transformers**.
